<!DOCTYPE HTML>
<html>
	<head>
		<title>CS 180 Project 4: Image Warping and Mosaicing</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<meta name="description" content="CS 180 Project 3: Face Morphing and Caricatures" />
		<meta name="keywords" content="CS, Computer Science, Face Morphing, Caricatures" />
		<link rel="stylesheet" href="assets/css/main.css" />

		<meta name="viewport" content="width=device-width, initial-scale=1.0">
		<style>
			body {
				font-family: 'Arial', sans-serif;
				font-size: 16px;
				line-height: 1.6;
				color: #333;
				margin: 20px;
				justify-content: center;
				align-items: center;
			}

			h1, h2, h3, h4, h5, h6 {
				font-family: 'Georgia', serif;
				color: #222;
			}

			p {
				margin-bottom: 15px;
			}

			a {
				color: #007BFF;
				text-decoration: none;
			}

			a:hover {
				text-decoration: underline;
			}

			.caption {
				font-size: 14px;
				color: #555;
			}

			.image-container {
				display: flex;
				justify-content: center;
				align-items: center;
				gap: 20px;
				margin: 20px 0;
			}

			.image-box {
				text-align: center;
			}

			.image-box img {
				border: 2px solid #000; /* Black border */
				box-shadow: 0 0 5px rgba(0,0,0,0.3); /* Optional: adds a subtle shadow */
			}

			img {
				max-width: 80%;
				height: auto;
				justify-content: center;
				align-items: center;
			}

			.image-container-large {
				display: flex;
				justify-content: center;
				align-items: center;
				gap: 20px;
				margin: 20px 0;
			}

			.image-container-large .image-box {
				text-align: center;
			}

			.image-container-large img {
				max-width: 100%;
				height: auto;
				justify-content: center;
				align-items: center;
				box-shadow: 2px 2px 8px rgba(0, 0, 0, 0.15);
			}

			.caption {
				white-space: pre-line;
				font-family: Arial, sans-serif;
				font-size: 14px;
			}

			.center {
				display: block;
				margin-left: auto;
				margin-right: auto;
				width: 60%;
			}
		</style>
	</head>
	<body class="is-preload">

		<!-- Wrapper -->
			<div id="wrapper">

				<!-- Intro -->
<section class="intro">
    <header>
        <h1>CS 180 Project: Image Mosaics</h1>
        <h1>Part A & B</h1>
        <h3>Table of Contents</h3>
        
        <!-- Part A -->
        <h4>Part A</h4>
        <ul class="actions">
            <li><a href="#part1" class="arrow scrolly"><span class="label">Introduction</span></a></li>
            <li><a href="#part2" class="arrow scrolly"><span class="label">Computing Homographies and Warping</span></a></li>
            <li><a href="#part3" class="arrow scrolly"><span class="label">Image Rectification</span></a></li>
            <li><a href="#part4" class="arrow scrolly"><span class="label">Mosaics</span></a></li>
        </ul>
        
        <!-- Part B -->
        <h4>Part B</h4>
        <ul class="actions">
            <li><a href="#part5" class="arrow scrolly"><span class="label">Detecting Corners</span></a></li>
            <li><a href="#part6" class="arrow scrolly"><span class="label">Extracting Feature Descriptors</span></a></li>
            <li><a href="#part7" class="arrow scrolly"><span class="label">Matching Feature Descriptors</span></a></li>
            <li><a href="#part8" class="arrow scrolly"><span class="label">Random Sample Consensus (RANSAC)</span></a></li>
            <li><a href="#part9" class="arrow scrolly"><span class="label">Autostitching Mosaics</span></a></li>
            <li><a href="#part10" class="arrow scrolly"><span class="label">Reflection</span></a></li>
        </ul>
    </header>
</section>

				<!-- Section -->
				<section id="part1">
					<header>
						<h2>Part 1. Introduction</h2>
					</header>
					<div class="content">
						<p>In Project 4A, I took a bunch of pictures, recovered homographies, warped images and then blended them together to form mosaics and panoramas.</p>
					</div>
				</section>

				<!-- Section -->
				<section id="part2">
					<header>
						<h2>Part 2: Computing Homographies and Warping</h2>
					</header>
					<div class="content">
						<p>The <code>compute_homography</code> function calculates the homography matrix between two sets of 
							corresponding points. The function takes two input arrays: points from the first image and corresponding points in the target image. 
							It constructs a system of linear equations and solves them using the least squares method to find the optimal homography 
							matrix.</p>
						
						<p>The <code>warp_image</code> function applies the computed homography to warp an input image. It uses the inverse of the homography matrix to map coordinates from the output image back to the input image. The function then uses bilinear interpolation to sample pixel values from the input image, ensuring smooth transitions between pixels in the warped result.</p>
					</div>
				</section>

				<!-- Section -->
				<section id="part3">
					<header>
						<h2>Part 3: Image Rectification</h2>
					</header>
					<div class="content">
						<p> I picked an assortment of things to rectify: a parking sign near my apartment, the whiteboard in Evans 1015 (ft. CS 180) and a lamppost. You can see the correspondence points I picked marked in red. I was particularly happy with the rectification of the lamppost given how small the region was. For the board, I drew out COMPSCI 180 in bubble letters to also verify that the transformation preserved text written on the same plane as the changes.</p>
						<div class="image-container">
							<div class="image-box">
								<img src="media/parking_rectified.png" alt="Original Parking" />

							</div>
						</div>
						<div class="image-container">
							<div class="image-box">
								<img src="media/board_rectified.jpg" alt="Original Parking" />

							</div>
						</div>
						<div class="image-container">
							<div class="image-box">
								<img src="media/lamppost_rectified.png" alt="Original Parking" />
							</div>
						</div>
					</div>
				</section>

					<!-- Section -->
<section id="part4">
    <header>
        <h2>Part 4: Mosaics</h2>
    </header>
    <div class="content">
        <p>I am a fan of landscapes so a lot of my mosaics stem from pictures I took from the Campanile (Northside, Bayview) and at the rooftop of the Standard (sosc, short for Social Sciences Bldg). 
			In addition, and for some variety, I also took a couple of pictures of my room and stitched them together to show that the process works for nearby objects as well.</p>

			<p>My approach was:</p>
			<ul>
				<li>Use the <a href="https://cal-cs180.github.io/fa23/hw/proj3/tool.html">correspondence tool from Project 3</a> to match features in two images</li>
				<li>Compute the midway points using them (<code>center_pts</code>)</li>
				<li>Project each image onto the midway points</li>
				<li>Create two masks using both <code>left_warped</code> and <code>right_warped</code></li>
				<li>Apply cv2.distanceTransform to get more gradual masks and prevent sharp lines</li>
				<li>Perform a weighted sum using these masks and normalize accordingly to get the combined image</li>
			</ul>

			<p>
			I included a naive combination of the two warped images by just taking an average as well. Some of the high filter features (like text in the wall picture) appear slightly blurry as they don't precisely line up with their opposing counterparts.
			I fiddled around with laplacian pyramids and sharpening but, in my opinion, it made the pictures worse. I attributed this to the warping step, wherein some pixels would necessarily get distributed across others when doing the bilinear interpolation. 
			This is particularly pronounced for wide-angle shots (like Bayview), and was unlikely to be fixed by emphasizing the high filter components.
			</p>
			
		<!-- SOSC Mosaic -->
        <h3>SOSC Mosaic</h3>

		For this first mosaic, I also included the left and right masks I obtained for each image.

			<div class="image-container">
				<div class="image-box">
					<img src="media/leftmask_mosaic_sosc.jpg" alt="SOSC Left Distance Transform Mask" />
					<p class="caption">SOSC: Left Mask</p>
				</div>
				<div class="image-box">
					<img src="media/rightmask_mosaic_sosc.jpg" alt="SOSC Right Distance Transform Mask" />
					<p class="caption">SOSC: Right Mask</p>
				</div>
			</div>
        
        <div class="image-box">
            <img src="media/og_mosaic_sosc.png" alt="SOSC Distance Transform Masks" />
            <p class="caption">SOSC: Distance Transform Masks</p>
        </div>
        <div class="image-box">
            <img src="media/warped_mosaic_sosc.png" alt="SOSC Warped Images" />
            <p class="caption">SOSC: Warped Images</p>
        </div>
        <div class="image-box">
            <img src="media/combined_mosaic_sosc.png" alt="SOSC Combined Images" />
            <p class="caption">SOSC: Naive Combine and Distance Transform</p>
        </div>

        <!-- Northside Mosaic -->
        <h3>Northside Mosaic</h3>
        <div class="image-box">
            <img src="media/og_mosaic_northside.png" alt="Northside Original Images" />
            <p class="caption">Northside: Original Images with Points</p>
        </div>
        <div class="image-box">
            <img src="media/warped_mosaic_northside.png" alt="Northside Warped Images" />
            <p class="caption">Northside: Warped Images</p>
        </div>
        <div class="image-box">
            <img src="media/combined_mosaic_northside.png" alt="Northside Combined Images" />
            <p class="caption">Northside: Naive Combine and Distance Transform</p>
        </div>

        <!-- Bayview Mosaic -->
        <h3>Bayview Mosaic</h3>
        <div class="image-box">
            <img src="media/og_mosaic_bayview.png" alt="Bayview Original Images" />
            <p class="caption">Bayview: Original Images with Points</p>
        </div>
        <div class="image-box">
            <img src="media/warped_mosaic_bayview.png" alt="Bayview Warped Images" />
            <p class="caption">Bayview: Warped Images</p>
        </div>
        <div class="image-box">
            <img src="media/combined_mosaic_bayview_vert.png" alt="Bayview Combined Images" />
            <p class="caption">Bayview: Naive Combine and Distance Transform</p>
        </div>

        <!-- Wall Mosaic -->
        <h3>Wall Mosaic</h3>
        <div class="image-box">
            <img src="media/og_mosaic_wall.png" alt="Wall Original Images" />
            <p class="caption">Wall: Original Images with Points</p>
        </div>
        <div class="image-box">
            <img src="media/warped_mosaic_wall.png" alt="Wall Warped Images" />
            <p class="caption">Wall: Warped Images</p>
        </div>
        <div class="image-box">
            <img src="media/combined_mosaic_wall.png" alt="Wall Combined Images" />
            <p class="caption">Wall: Naive Combine and Distance Transform</p>
        </div>
    </div>
</section>

<!-- Section -->
<section id="part5">
    <header>
		<h1>Part B</h1>
        <h2>Detecting Corners</h2>
    </header>
    <div class="content">
        <p>In my implementation, I began by detecting corners using the Harris algorithm through <code>get_harris_corners()</code>. After extracting the corner scores into a vector using <code>scores = h[corners[:, 0], corners[:, 1]]</code>, I moved on to applying Adaptive Non-Maximal Suppression (ANMS). This crucial step helps me identify the strongest corners while ensuring they remain evenly distributed across the image.</p>

    <p>The ANMS process required me to calculate pairwise distances using <code>dist2()</code>. I leveraged numpy broadcasting to check if <code>f(x_i) < c_robust * f(x_j)</code> held true for each corner pair, creating a <code>larger_mask</code>. By applying this mask to my distances through <code>masked_dists = dists * larger_mask</code>, I effectively set non-qualifying corner pairs to infinity to exclude them from minimization.</p>

    <p>Computing the minimum radii for each point was my next step, which I accomplished with <code>radii = np.min(masked_dists, axis=1)</code>. To finalize the process, I sorted the indices by decreasing radii and used these to reorder my original corner list. With a simple slice of <code>points = sorted_corners[:num_corners]</code>, I obtained my best corners. For this project, I used num_corners=200. </p>

    <div class="image-container">
        <div class="image-box">
            <img src="media\harris_sosc.jpg" alt="ANMS SOSC">
            <div class="caption">Harris Corner Detection</div>
        </div>

		<div class="image-box">
			<img src="media\anms_sosc.jpg" alt="Harris SOSC">
			<div class="caption">ANMS Corner Detection</div>
		</div>
    </div>

	I combined the plots above for the rest of the pictures to show all the harris corners (blue) and also the corners left after ANMS (orange). Note how in the pictures with rectangular buildings (Evans, Social Sciences Building), how the edges are picked up quite well even after ANMS.

	<div class="image-container">
        <div class="image-box">
            <img src="media\anms_harris_wall.png" alt="ANMS SOSC">
            <div class="caption">ANMS + Harris Corner Detection (Wall)</div>
        </div>

		<div class="image-box">
            <img src="media\anms_harris_northside.png" alt="ANMS SOSC">
            <div class="caption">ANMS + Harris Corner Detection (Northside)</div>
        </div>

		<div class="image-box">
            <img src="media\anms_harris_arch.png" alt="ANMS SOSC">
            <div class="caption">ANMS + Harris Corner Detection (Arch)</div>
        </div>
    </div>

	<div class="image-container">
        

		<div class="image-box">
            <img src="media\anms_harris_oakland.png" alt="ANMS SOSC">
            <div class="caption">ANMS + Harris Corner Detection (Oakland)</div>
        </div>
    </div>

	<div class="image-box">
		<img src="media\anms_harris_bayview.png" alt="ANMS SOSC">
		<div class="caption">ANMS + Harris Corner Detection (Bayview)</div>
	</div>

	<p>As an interesting failure case for if you don't specify enough corners, consider the following outcome when num_corners=50.</p>

	<div class="image-box">
		<img src="media\failure_auto_og_mosaic_sosc.png" alt="ANMS SOSC">
		<div class="caption">Failure: Not enough points</div>
	</div>
	<div class="image-box">
		<img src="media\failure_auto_final_sosc.jpg" alt="Harris SOSC">
		<div class="caption">Failure: Warped to another dimension</div>
	</div>

</section>

<!-- Section -->
<section id="part6">
    <header>
        <h2>Extracting Feature Descriptors</h2>
    </header>
    <div class="content">

		<p>I implemented a series of functions to extract and process image features around detected corner points. The process begins with <code>extract_patch(image, point, patch_size=40)</code>, which extracts a 40x40 pixel square centered on each corner point. It carefully handles edge cases by skipping corners too close to image boundaries.</p>

		<p>These patches then undergo two transformations. First, <code>downsample_patch(patch)</code> reduces each patch to 20% of its original size using scikit-image's rescaling function with channel_axis=2. Then, <code>normalize_patch(patch)</code> standardizes the patch by subtracting its mean and dividing by its standard deviation, making features more robust to lighting variations.</p>
		
		<p>Finally, <code>extract_features(image, corners)</code> ties everything together, processing each corner point through this pipeline. It maintains lists of both the original downsampled features and their normalized versions, while also tracking which corner points produced valid patches. This comprehensive approach ensures we have reliable feature descriptors for matching across images. Below I show both the unnormalized features (easier to understand and display) and the normalized features.</p>
    <div class="image-container">
        <div class="image-box">
            <img src="media\unnormed_features_sosc.png" alt="Normed Features SOSC">
            <div class="caption">Unnormalized Features (Social Sciences Bldg)</div>
        </div>
    </div>

	<div class="image-box">
		<img src="media\normed_features_sosc.png" alt="Unnormed Features SOSC">
		<div class="caption">Normalized Features (Social Sciences Bldg)</div>
	</div>


	For general reference, the unnormalized features for bayview, northside, oakland and wall are also shown below:

	<div class="image-box">
		<img src="media\unnormed_features_bayview.png" alt="Normed Features SOSC">
		<div class="caption">Unnormalized Features (Bayview)</div>
	</div>
	<div class="image-box">
		<img src="media\unnormed_features_wall.png" alt="Normed Features SOSC">
		<div class="caption">Unnormalized Features (Wall)</div>
	</div>
	<div class="image-box">
		<img src="media\unnormed_features_northside.png" alt="Normed Features SOSC">
		<div class="caption">Unnormalized Features (Northside)</div>
	</div>
	<div class="image-box">
		<img src="media\unnormed_features_arch.png" alt="Normed Features SOSC">
		<div class="caption">Unnormalized Features (Arch)</div>
	</div>
	<div class="image-box">
		<img src="media\unnormed_features_oakland.png" alt="Normed Features SOSC">
		<div class="caption">Unnormalized Features (Oakland)</div>
	</div>

</section>

<!-- Section -->
<section id="part7">
    <header>
        <h2>Matching Feature Descriptors</h2>
    </header>
    <div class="content">

		<p>To match features between images, I implemented a function that computes the Sum of Squared Differences (SSD) between all possible feature pairs. For each feature in the first image, it finds its two closest matches in the second image. Following Lowe's ratio test, I only keep matches where the best match is significantly better than the second-best (controlled by the ratio threshold of 0.3). This helps eliminate ambiguous matches, returning only the most reliable feature correspondences between the two images.</p>
		<p>Pay attention to the red point in the top left corner of the Social Sciences Bldg picture, and the point near Mt. Tamalpais in the bayview picture. We shall revisit them after RANSAC to see if they made the cut.</p>
        <div class="image-box">
            <img src="media\actual_matched_features_sosc.png" alt="SOSC Matched Features">
            <div class="caption">Matched Features</div>
        </div>

		<div class="image-box">
            <img src="media\actual_matched_features_bayview.png" alt="SOSC Matched Features">
            <div class="caption">Matched Features</div>
        </div>
</section>

<!-- Section -->
<section id="part8">
    <header>
        <h2>RANdom Sample Consensus (RANSAC)</h2>
    </header>
    <div class="content">
		<p>Points that fall within a 5-pixel threshold of their expected positions are considered inliers - these are matches that are geometrically consistent with the current homography. If the current iteration finds more inliers than any previous attempt, I update my "best" homography and save the mask identifying these inlier points. This approach ensures that outliers (incorrect matches) don't influence the final transformation, as they're unlikely to consistently agree with the correct geometric relationship between the images.</p>

		<p>Finally, once I've identified the set of inlier points that yield the best consensus, I refine the homography by recomputing it using all inlier points rather than just the initial four. This refinement step produces a more accurate transformation that captures the true geometric relationship between the images.</p>
		
		<p>As you can see below, the red point in the top left portion of the picture in the Matched Features section is no longer present after RANSAC. While the "edges" within the sky look similar, because they are not consistent with the all the other correspondences, they are not included.</p>
	<div class="image-box">
		<img src="media\sosc_matched_features.png" alt="Matched Features Bayview">
		<div class="caption">Matched Features after RANSAC (Bayview)</div>
	</div>

	<p>You can note that the point at Mt. Tamalpais was also excluded after RANSAC. I have also included the matched features after RANSAC for the other mosaics created, which you could expect to be slightly different to matched features before RANSAC:</p>
	
    <div class="image-box">
        <img src="media\matched_features_bayview.png" alt="Matched Features Bayview">
        <div class="caption">Matched Features after RANSAC (Bayview)</div>
    </div>
    <div class="image-box">
        <img src="media\matched_features_wall.png" alt="Matched Features Wall">
        <div class="caption">Matched Features after RANSAC (Wall)</div>
    </div>
    <div class="image-box">
        <img src="media\matched_features_northside.png" alt="Matched Features Northside">
        <div class="caption">Matched Features after RANSAC (Northside)</div>
    </div>
    <div class="image-box">
        <img src="media\matched_features_arch.png" alt="Matched Features Arch">
        <div class="caption">Matched Features after RANSAC (Arch)</div>
    </div>
    <div class="image-box">
        <img src="media\matched_features_oakland.png" alt="Matched Features Oakland">
        <div class="caption">Matched Features after RANSAC (Oakland)</div>
    </div>
</section>

<!-- Section -->
<section id="part9">
    <header>
        <h2>Autostitching Mosaics</h2>
    </header>
    <div class="content">

	<p>This part was simple given that all the setup was done in Part A. Now that we automatically obtain a reliable set of correspondences between two images, we can once again find the center points, compute the homography that warps the images accordingly and then blend them. I did not use the homography returned by RANSAC since I was combining them in this particular fashion.</p>

	<p>I was pleasantly surprised with the results. The pictures were less blurry than when I manually did the correspondences, likely because I could not be as precise with the pixels. This is particularly evident with the wall picture, where the writing isn't as blurred as before. This also provided further confirmation that additional blending would not have helped because I was simply limited by the manual correspondences. Moreover, there were simply more correspondences automatically found (especially prevalent in the wall, northside pictures) than I found and that made the results more reliable.</p>
	<div class="image-container">
		<div class="image-box">
            <img src="media\manual_final_sosc.jpg" alt="Normed Features SOSC">
            <div class="caption">Manual Final Mosaic</div>
        </div>
        <div class="image-box">
            <img src="media\auto_final_sosc.jpg" alt="Normed Features SOSC">
            <div class="caption">Auto Final Mosaic</div>
        </div>
    </div>

	<div class="image-box">
		<img src="media\manual_final_bayview.jpg" alt="Normed Features SOSC">
		<div class="caption">Manual Final Mosaic</div>
	</div>
	<div class="image-box">
		<img src="media\auto_final_bayview.jpg" alt="Normed Features SOSC">
		<div class="caption">Auto Final Mosaic</div>
	</div>

	<div class="image-container">
		<div class="image-box">
            <img src="media\manual_final_wall.jpg" alt="Normed Features SOSC">
            <div class="caption">Manual Final Mosaic</div>
        </div>
        <div class="image-box">
            <img src="media\auto_final_wall copy.jpg" alt="Normed Features SOSC">
            <div class="caption">Auto Final Mosaic</div>
        </div>
    </div>

	<div class="image-container">
		<div class="image-box">
            <img src="media\manual_final_northside.jpg" alt="Normed Features SOSC">
            <div class="caption">Manual Final Mosaic</div>
        </div>
        <div class="image-box">
            <img src="media\auto_final_northside.jpg" alt="Normed Features SOSC">
            <div class="caption">Auto Final Mosaic</div>
        </div>
    </div>

	<div class="image-container">
        <div class="image-box">
            <img src="media\auto_final_arch.jpg" alt="Normed Features SOSC">
            <div class="caption">Auto Mosaic (no Manual)</div>
        </div>
    </div>

	<div class="image-container">
        <div class="image-box">
            <img src="media\auto_final_oakland.jpg" alt="Normed Features SOSC">
            <div class="caption">Auto Mosaic (no Manual)</div>
        </div>
    </div>

	</div>
</section>

<!-- Section -->
<section id="part10">
    <header>
        <h2>Reflections</h2>
    </header>
    <div class="content">
		<p>
		In terms of cool things I learned, I realised I am bad at manually doing correspondences. Automatically stitching images was ultimately (1) more efficient in terms of time (2) but also better quality on average. The process of extracting features was also super cool as it sort of felt like a precursor to all the more complicated stuff that comes with CNNs and learned filters.</p>

		<p>I'm also inspired to try cool new types of panoramas. I recently rewatched Spiderman: Across the Spiderverse recently, and the second I saw this shot I saw there was scope to do something. While the manual correspondences were possible, doing it automatically just felt so much cooler. Fun bonus result below, using screenshots from the movie:
	</p>
	<div class="image-box">
		<img src="media\auto_og_mosaic_spiderverse.png" alt="Normed Features SOSC">
		<div class="caption">Final Mosaic</div>
	</div>

	<div class="image-container">
		
        <div class="image-box">
            <img src="media\auto_final_spiderverse1.jpg" alt="Normed Features SOSC">
            <div class="caption">Final Mosaic</div>
        </div>
    </div>

	</section>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/jquery.scrolly.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>

	</body>
</html>